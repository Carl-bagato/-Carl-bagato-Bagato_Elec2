# -*- coding: utf-8 -*-
"""Bagato_Elec2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fL6T6BWVz0kxrJW4SItViYbAtLQCoaLr
"""

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, desc
from pyspark.sql.functions import when
from pyspark.sql.functions import avg

# Initialize Spark session
spark = SparkSession.builder.appName("PartitioningExample").getOrCreate()

# Load the dataset (Ensure correct file path)
file_path = "/content/hotel_bookings.csv"
df = spark.read.csv(file_path, header=True, inferSchema=True)

# Show schema to understand the data
df.printSchema()

# Partitioning Strategy 1: Partition by 'hotel' column
df_partitioned = df.repartition("hotel")

# Partitioning Strategy 2: Repartition into a fixed number of partitions (e.g., 4)
df_repartitioned = df.repartition(4)

# Transformation Pipeline
# 1. Summarize data - Count bookings per hotel type
summary_df = df.groupBy("hotel").agg(count("*").alias("booking_count"))

# 2. Sorting - Sort by arrival_date_year and arrival_date_month
sorted_df = df.orderBy(desc("arrival_date_year"), desc("arrival_date_month"))

# 3. Filtering - Filter bookings for a specific country (e.g., 'USA')
filtered_df = df.filter(col("country") == "USA")

# Show results
print("Summary of Bookings per Hotel Type:")
summary_df.show()

print("Sorted Bookings by Arrival Date:")
sorted_df.show(5)  # Show top 5 sorted results

print("Filtered Bookings for USA:")
filtered_df.show(5)  # Show top 5 results



# Filter the dataset for the years 2015, 2016, and 2017
df_filtered_years = df.filter((col("arrival_date_year") == 2015) |
                              (col("arrival_date_year") == 2016) |
                              (col("arrival_date_year") == 2017))

# Partitioning Strategy 4: Range Partitioning by 'adr' and 'arrival_date_year'
df_range_partitioned = df_filtered_years.repartitionByRange("adr", "arrival_date_year")

print("Range Partitioning by 'adr' and 'arrival_date_year' done!")

# Transformation 3: Summarize bookings by 'adr' range and year (Low, Medium, High)
adr_summary_df = df_filtered_years.withColumn("adr_range",
    when(col("adr") < 50, "Low")
    .when((col("adr") >= 50) & (col("adr") < 150), "Medium")
    .otherwise("High")
).groupBy("arrival_date_year", "adr_range").agg(count("*").alias("booking_count"))

# Show the summarized results
print("Summary of Bookings by 'adr' Range and Year (2015, 2016, 2017):")
adr_summary_df.orderBy("arrival_date_year", "adr_range").show()


# Transformation 4: Calculate the average 'adr' per year (2015, 2016, 2017)
adr_avg_df = df_filtered_years.groupBy("arrival_date_year").agg(avg("adr").alias("average_adr"))

# Show the average adr per year
print("Average ADR per Year (2015, 2016, 2017):")
adr_avg_df.orderBy("arrival_date_year").show()